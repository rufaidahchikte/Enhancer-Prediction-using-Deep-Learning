{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa113d62-6621-4b07-b39c-475ffef2c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### download .bed from screen dataset and view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af07f5c-f3eb-46dc-955e-368d657fcad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_bed_with_pandas(filename):\n",
    "    \"\"\"Reads a space-delimited .bed file into a pandas DataFrame.\"\"\"\n",
    "    # Define column names for a BED6 format.\n",
    "    # Adjust if your file has more or fewer columns.\n",
    "    col_names = ['chrom', 'chromStart', 'chromEnd', 'name', 'score', 'strand']\n",
    "\n",
    "    # Use sep='\\s+' to split by one or more spaces.\n",
    "    df = pd.read_csv(filename, sep='\\s+', header=None, names=col_names,\n",
    "                     comment='#')\n",
    "    return df\n",
    "\n",
    "# Make sure the file path is correct\n",
    "bed_df = read_bed_with_pandas('GRCh38-cCREs.with_seq.clean.bed') #GRCh38-cCREs.with_seq.clean.bed #GRCh38-cCREs.bed\n",
    "print(bed_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f9bba75-01dc-49da-b5a8-9764cfe60e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2348854\n"
     ]
    }
   ],
   "source": [
    "print(len(bed_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3ef31d-6799-42f8-b46a-ee72040d2efe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Downloading sequence data to be merged with our .bed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fcd7685-70be-45bf-b8e2-86f3dddfe0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting .fna file with chromosomes written in different style (NC_000001.11) to our BED styles (chr1) in .fa format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5514c-44b7-4f41-ad08-4d512e35eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "src = \"/Users/rufaidah/Downloads/ncbi_dataset/ncbi_dataset/data/GCF_000001405.26/GCF_000001405.26_GRCh38_genomic.fna\"\n",
    "dst = \"/Users/rufaidah/Downloads/ncbi_dataset/ncbi_dataset/data/GCF_000001405.26/GRCh38.primary.ucsc.fa\"\n",
    "\n",
    "# Map RefSeq accessions to UCSC names\n",
    "refseq_to_ucsc = {\n",
    "    \"NC_000001.11\":\"chr1\",  \"NC_000002.12\":\"chr2\",  \"NC_000003.12\":\"chr3\",\n",
    "    \"NC_000004.12\":\"chr4\",  \"NC_000005.10\":\"chr5\",  \"NC_000006.12\":\"chr6\",\n",
    "    \"NC_000007.14\":\"chr7\",  \"NC_000008.11\":\"chr8\",  \"NC_000009.12\":\"chr9\",\n",
    "    \"NC_000010.11\":\"chr10\", \"NC_000011.10\":\"chr11\", \"NC_000012.12\":\"chr12\",\n",
    "    \"NC_000013.11\":\"chr13\", \"NC_000014.9\":\"chr14\",  \"NC_000015.10\":\"chr15\",\n",
    "    \"NC_000016.10\":\"chr16\", \"NC_000017.11\":\"chr17\", \"NC_000018.10\":\"chr18\",\n",
    "    \"NC_000019.10\":\"chr19\", \"NC_000020.11\":\"chr20\", \"NC_000021.9\":\"chr21\",\n",
    "    \"NC_000022.11\":\"chr22\", \"NC_000023.11\":\"chrX\",  \"NC_000024.10\":\"chrY\",\n",
    "    \"NC_012920.1\":\"chrM\",   # mitochondrial\n",
    "}\n",
    "\n",
    "def header_to_ucsc(h):\n",
    "    # h like: \">NC_000001.11 Homo sapiens chromosome 1, GRCh38 Primary Assembly\"\n",
    "    acc = h[1:].split()[0]  # take token after '>', up to first whitespace\n",
    "    return \">\" + refseq_to_ucsc.get(acc, \"\")  # empty if not a primary we keep\n",
    "\n",
    "with open(src) as fin, open(dst, \"w\") as fout:\n",
    "    keep = False\n",
    "    for line in fin:\n",
    "        if line.startswith(\">\"):\n",
    "            newh = header_to_ucsc(line.strip())\n",
    "            if newh and len(newh) > 1:\n",
    "                fout.write(newh + \"\\n\")\n",
    "                keep = True\n",
    "            else:\n",
    "                keep = False  # skip scaffolds/unplaced/alt contigs\n",
    "        else:\n",
    "            if keep:\n",
    "                fout.write(line)\n",
    "print(\"Wrote:\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "619563ab-b319-4836-891c-530f02b8ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0eb441-5851-4e44-8b8a-a5c406dfe0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfaidx import Fasta\n",
    "\n",
    "fasta = Fasta(\"/Users/rufaidah/Downloads/ncbi_dataset/ncbi_dataset/data/GCF_000001405.26/GRCh38.primary.ucsc.fa\")\n",
    "\n",
    "out_path = \"/Users/rufaidah/Downloads/ncbi_dataset/ncbi_dataset/data/GCF_000001405.26/GRCh38-cCREs.with_seq.bed\"\n",
    "\n",
    "with open(\"/Users/rufaidah/Downloads/ncbi_dataset/ncbi_dataset/data/GCF_000001405.26/GRCh38-cCREs.bed\") as bed, open(out_path, \"w\") as out:\n",
    "    for line in bed:\n",
    "        if line.startswith(\"#\") or not line.strip():\n",
    "            continue\n",
    "        chrom, start, end, *rest = line.strip().split(\"\\t\")\n",
    "        seq = fasta[chrom][int(start):int(end)].seq.upper()\n",
    "        out.write(\"\\t\".join([chrom, start, end, *rest, seq]) + \"\\n\")\n",
    "\n",
    "print(\"✅ Wrote sequences to\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362384d-c41a-4272-be04-76ce779f1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renaming columns for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b4bee-0016-4ca7-90f3-7fd7eeb3017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"GRCh38-cCREs.with_seq.bed\"\n",
    "\n",
    "# Peek at the first line to detect a header\n",
    "with open(path) as f:\n",
    "    first = f.readline().strip()\n",
    "\n",
    "has_header = first.lower().startswith((\"chrom\", \"#chrom\"))\n",
    "\n",
    "# Read with/without header accordingly\n",
    "if has_header:\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=0, comment=\"#\", dtype=str, low_memory=False)\n",
    "else:\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=None, comment=\"#\", dtype=str, low_memory=False)\n",
    "    # assign expected BED+seq names for 7 columns\n",
    "    df.columns = [\"chrom\",\"start\",\"end\",\"dhs_id\",\"ccre_id\",\"type\",\"sequence\"][:df.shape[1]]\n",
    "\n",
    "# Some files use UCSC-style names for start/end; unify to start/end\n",
    "rename_map = {\n",
    "    \"chromStart\":\"start\",\n",
    "    \"chromEnd\":\"end\",\n",
    "    \"name\":\"dhs_id\",\n",
    "    \"score\":\"ccre_id\",\n",
    "    \"strand\":\"type\",\n",
    "}\n",
    "df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "# Ensure the key columns exist in order\n",
    "cols = [\"chrom\",\"start\",\"end\",\"dhs_id\",\"ccre_id\",\"type\",\"sequence\"]\n",
    "df = df[[c for c in cols if c in df.columns]]\n",
    "\n",
    "# Fix types and index\n",
    "df[\"start\"] = pd.to_numeric(df[\"start\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df[\"end\"]   = pd.to_numeric(df[\"end\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df.head(3))\n",
    "print(df.dtypes)\n",
    "\n",
    "# (Optional) save a clean, canonical version\n",
    "df.to_csv(\"GRCh38-cCREs.with_seq.clean.bed\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0685c0-5be6-4630-9678-76cef6174bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tissue data\n",
    "## Download data for each tissue then merge with our dataset based on chrom start and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0dc18-864e-481a-9ea5-9e3dcee564d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# ========= USER INPUT =========\n",
    "MASTER = \"GRCh38-cCREs.with_seq.clean.bed\"   # your validated BED+sequence file\n",
    "# Either list explicit files...\n",
    "TISSUE_FILES = [\n",
    "    # e.g. \"brain.noccl.cCREs.bed\", \"blood.noccl.cCREs.bed\", ...\n",
    "    # Or leave this list empty and use the glob below.\n",
    "]\n",
    "# ...or use a glob pattern to pick your selected tissues in the current folder:\n",
    "if not TISSUE_FILES:\n",
    "    TISSUE_FILES = sorted(glob(\"*.cCREs*.bed\"))  # adjust if needed\n",
    "# Pick at most 10 tissues if you want:\n",
    "MAX_TISSUES = 10\n",
    "TISSUE_FILES = TISSUE_FILES[:MAX_TISSUES]\n",
    "\n",
    "# Enhancer-only definition:\n",
    "ACTIVE_LABELS = {\"pels\", \"dels\"}   # case-insensitive\n",
    "# ==============================\n",
    "\n",
    "\n",
    "def tissue_name_from_path(p):\n",
    "    base = os.path.basename(p)\n",
    "    # strip common suffixes\n",
    "    for tag in [\".noccl.cCREs\", \".all.cCREs\", \".cCREs\", \".bed\"]:\n",
    "        base = base.replace(tag, \"\")\n",
    "    base = base.replace(\"..\", \".\")\n",
    "    return base.strip(\".\").replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "def detect_label_col(path, sample_rows=20000):\n",
    "    \"\"\"Heuristically find which column holds class labels (pELS/dELS/PLS/CA-* or DNase).\"\"\"\n",
    "    sample = pd.read_csv(path, sep=\"\\t\", header=None, nrows=sample_rows, comment=\"#\", dtype=str)\n",
    "    known_tokens = {\n",
    "        \"PLS\",\"PELS\",\"DELS\",\n",
    "        \"CA-CTCF\",\"CA-TF\",\"CA-ONLY\",\"CA-H3K4ME3\",\n",
    "        \"LOW-DNASE\",\"MEDIUM-DNASE\",\"HIGH-DNASE\",\"VERY-LOW-DNASE\",\"NONE\"\n",
    "    }\n",
    "    best_col, best_hit = None, -1.0\n",
    "    for col in sample.columns:\n",
    "        vals = sample[col].dropna().astype(str).str.strip().str.upper()\n",
    "        hit = (vals.isin(known_tokens)).mean()\n",
    "        if hit > best_hit:\n",
    "            best_hit = float(hit)\n",
    "            best_col = col\n",
    "    return best_col, best_hit\n",
    "\n",
    "\n",
    "def load_tissue_scores(path, verbose=True):\n",
    "    \"\"\"Return a dataframe with (chrom,start,end, score_<tissue>) using auto-detected label column.\"\"\"\n",
    "    label_col, hit = detect_label_col(path)\n",
    "    if verbose:\n",
    "        print(f\"[{os.path.basename(path)}] label_col={label_col}  hit_frac={hit:.3f}\")\n",
    "    usecols = [0,1,2,label_col]  # chrom, start, end, label\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=None, usecols=usecols, comment=\"#\", dtype=str, low_memory=False)\n",
    "    df.columns = [\"chrom\",\"start\",\"end\",\"score_raw\"]\n",
    "    # Clean types and strings\n",
    "    df[\"chrom\"] = df[\"chrom\"].astype(str).str.strip()\n",
    "    df[\"start\"] = pd.to_numeric(df[\"start\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"end\"]   = pd.to_numeric(df[\"end\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"score\"] = df[\"score_raw\"].fillna(\"\").astype(str).str.strip()\n",
    "    df = df.dropna(subset=[\"chrom\",\"start\",\"end\"]).copy()\n",
    "    # Keep only needed columns\n",
    "    df = df[[\"chrom\",\"start\",\"end\",\"score\"]]\n",
    "    return df\n",
    "\n",
    "\n",
    "# 1) Load master and normalize column names/order\n",
    "master = pd.read_csv(MASTER, sep=\"\\t\", dtype=str)\n",
    "rename_map = {\n",
    "    \"chromStart\":\"start\", \"chromEnd\":\"end\",\n",
    "    \"name\":\"dhs_id\",\"score\":\"ccre_id\",\"strand\":\"type\"\n",
    "}\n",
    "master.rename(columns={k:v for k,v in rename_map.items() if k in master.columns}, inplace=True)\n",
    "\n",
    "# keep canonical columns if present\n",
    "cols = [c for c in [\"chrom\",\"start\",\"end\",\"dhs_id\",\"ccre_id\",\"type\",\"sequence\"] if c in master.columns]\n",
    "master = master[cols].copy()\n",
    "\n",
    "# force numeric types for coordinates\n",
    "master[\"start\"] = pd.to_numeric(master[\"start\"], errors=\"coerce\").astype(\"Int64\")\n",
    "master[\"end\"]   = pd.to_numeric(master[\"end\"], errors=\"coerce\").astype(\"Int64\")\n",
    "master[\"chrom\"] = master[\"chrom\"].astype(str).str.strip()\n",
    "master = master.dropna(subset=[\"chrom\",\"start\",\"end\"]).copy()\n",
    "\n",
    "print(f\"Loaded master: {MASTER}  rows={len(master):,}\")\n",
    "\n",
    "# 2) Merge each tissue (by chrom,start,end), add score_<tissue> and active_<tissue> (pELS/dELS=1)\n",
    "for tp in TISSUE_FILES:\n",
    "    tname = tissue_name_from_path(tp)\n",
    "    tdf = load_tissue_scores(tp)\n",
    "    # merge on coordinates\n",
    "    master = master.merge(\n",
    "        tdf.rename(columns={\"score\": f\"score_{tname}\"}),\n",
    "        on=[\"chrom\",\"start\",\"end\"], how=\"left\"\n",
    "    )\n",
    "    # binary enhancer-only flag\n",
    "    col_score = f\"score_{tname}\"\n",
    "    col_active = f\"active_{tname}\"\n",
    "    master[col_active] = master[col_score].str.lower().isin(ACTIVE_LABELS).astype(\"Int64\")\n",
    "    # (Optional) print quick counts\n",
    "    n_active = int(master[col_active].sum(skipna=True))\n",
    "    print(f\" - merged {tname:20s} | active (pELS/dELS) = {n_active:,}\")\n",
    "\n",
    "# 3) Save the merged matrix\n",
    "OUT = \"GRCh38-cCREs.with_seq.enhancer_merged.bed\"\n",
    "master.to_csv(OUT, sep=\"\\t\", index=False)\n",
    "print(f\"\\n✅ Wrote: {OUT}\")\n",
    "\n",
    "# 4) Small summary for your chosen tissues\n",
    "active_cols = [c for c in master.columns if c.startswith(\"active_\")]\n",
    "summary = {c: int(master[c].sum(skipna=True)) for c in active_cols}\n",
    "print(\"\\nActive counts per tissue (pELS/dELS):\")\n",
    "for k,v in sorted(summary.items(), key=lambda kv: -kv[1]):\n",
    "    print(f\"{k:25s} {v:,}\")\n",
    "\n",
    "print(f\"\\nRows in final table: {len(master):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e94ff6ea-90db-4475-b023-de18bd354b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final step before feature engineering\n",
    "## Converting chrom type to binary (1 for enhancer and 0 for others), same for the tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a74465-255e-4f21-8ff9-2c80e8d67195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "IN  = \"GRCh38-cCREs.with_seq.enhancer_merged.bed\"\n",
    "OUT_FULL    = \"GRCh38-cCREs.trainready.full.tsv\"\n",
    "OUT_MINIMAL = \"GRCh38-cCREs.trainready.minimal.tsv\"\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(IN, sep=\"\\t\", low_memory=False, dtype=str)\n",
    "\n",
    "# --- 1) Make enhancer label from 'type': 1 if pELS/dELS, else 0 ---\n",
    "def to_label(x: str) -> int:\n",
    "    if not isinstance(x, str):\n",
    "        return 0\n",
    "    x = x.strip().lower()\n",
    "    return 1 if x in {\"pels\", \"dels\"} else 0\n",
    "\n",
    "if \"type\" not in df.columns:\n",
    "    raise ValueError(\"Column 'type' not found. Make sure input file has the cCRE type column.\")\n",
    "\n",
    "df[\"enhancer_label\"] = df[\"type\"].apply(to_label).astype(\"int8\")\n",
    "\n",
    "# --- 2) Drop all score_* columns (we keep active_* binaries) ---\n",
    "score_cols = [c for c in df.columns if c.startswith(\"score_\")]\n",
    "df.drop(columns=score_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# --- 3) Coerce numeric coords if present ---\n",
    "for c in (\"start\", \"end\"):\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# --- 4) Save FULL version (coords/IDs/sequence/label + active_* flags) ---\n",
    "df.to_csv(OUT_FULL, sep=\"\\t\", index=False)\n",
    "\n",
    "# --- 5) Save MINIMAL version (sequence + enhancer_label + all active_* flags) ---\n",
    "active_cols = [c for c in df.columns if c.startswith(\"active_\")]\n",
    "keep_min = [\"sequence\", \"enhancer_label\"] + active_cols\n",
    "keep_min = [c for c in keep_min if c in df.columns]\n",
    "df[keep_min].to_csv(OUT_MINIMAL, sep=\"\\t\", index=False)\n",
    "\n",
    "# --- 6) Quick summary ---\n",
    "n = len(df)\n",
    "pos = int(df[\"enhancer_label\"].sum())\n",
    "neg = n - pos\n",
    "print(f\"Rows: {n:,} | Enhancers (pELS/dELS): {pos:,} | Non-enhancers: {neg:,}\")\n",
    "print(f\"Dropped score columns: {len(score_cols)} -> {score_cols[:5]}{' ...' if len(score_cols)>5 else ''}\")\n",
    "print(f\"✅ Wrote:\\n - {OUT_FULL}\\n - {OUT_MINIMAL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
